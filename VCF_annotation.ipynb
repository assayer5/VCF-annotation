{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a000a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, json, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "567f4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name\n",
    "filename = 'test_vcf_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4eee3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of header lines: 48\n"
     ]
    }
   ],
   "source": [
    "# check how many lines of headers are in file, where headers start with \"##\"\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    \n",
    "    headercount=0\n",
    "    line = file.readline()\n",
    "    \n",
    "    while line.startswith('##'):\n",
    "        headercount +=1\n",
    "        line = file.readline()\n",
    "        \n",
    "print('Number of header lines:', headercount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeda4cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>QUAL</th>\n",
       "      <th>FILTER</th>\n",
       "      <th>INFO</th>\n",
       "      <th>FORMAT</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1158631</td>\n",
       "      <td>.</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>2965</td>\n",
       "      <td>PASS</td>\n",
       "      <td>BRF=0.16;FR=1.0000;HP=1;HapScore=1;MGOF=3;MMLQ...</td>\n",
       "      <td>GT:GL:GOF:GQ:NR:NV</td>\n",
       "      <td>1/1:-300.0,-43.88,0.0:3:99:160:156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1246004</td>\n",
       "      <td>.</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>2965</td>\n",
       "      <td>PASS</td>\n",
       "      <td>BRF=0.09;FR=1.0000;HP=6;HapScore=1;MGOF=5;MMLQ...</td>\n",
       "      <td>GT:GL:GOF:GQ:NR:NV</td>\n",
       "      <td>1/1:-300.0,-41.24,0.0:5:99:152:148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1249187</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>2965</td>\n",
       "      <td>PASS</td>\n",
       "      <td>BRF=0.16;FR=1.0000;HP=3;HapScore=1;MGOF=3;MMLQ...</td>\n",
       "      <td>GT:GL:GOF:GQ:NR:NV</td>\n",
       "      <td>1/1:-300.0,-37.63,0.0:3:99:137:135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1261824</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>2965</td>\n",
       "      <td>PASS</td>\n",
       "      <td>BRF=0.15;FR=1.0000;HP=1;HapScore=1;MGOF=5;MMLQ...</td>\n",
       "      <td>GT:GL:GOF:GQ:NR:NV</td>\n",
       "      <td>1/1:-300.0,-39.74,0.0:5:99:136:134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1387667</td>\n",
       "      <td>.</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>2965</td>\n",
       "      <td>PASS</td>\n",
       "      <td>BRF=0.17;FR=1.0000;HP=2;HapScore=1;MGOF=3;MMLQ...</td>\n",
       "      <td>GT:GL:GOF:GQ:NR:NV</td>\n",
       "      <td>1/1:-300.0,-39.41,0.0:3:99:137:133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  #CHROM      POS ID REF ALT  QUAL FILTER  \\\n",
       "0      1  1158631  .   A   G  2965   PASS   \n",
       "1      1  1246004  .   A   G  2965   PASS   \n",
       "2      1  1249187  .   G   A  2965   PASS   \n",
       "3      1  1261824  .   G   C  2965   PASS   \n",
       "4      1  1387667  .   C   G  2965   PASS   \n",
       "\n",
       "                                                INFO              FORMAT  \\\n",
       "0  BRF=0.16;FR=1.0000;HP=1;HapScore=1;MGOF=3;MMLQ...  GT:GL:GOF:GQ:NR:NV   \n",
       "1  BRF=0.09;FR=1.0000;HP=6;HapScore=1;MGOF=5;MMLQ...  GT:GL:GOF:GQ:NR:NV   \n",
       "2  BRF=0.16;FR=1.0000;HP=3;HapScore=1;MGOF=3;MMLQ...  GT:GL:GOF:GQ:NR:NV   \n",
       "3  BRF=0.15;FR=1.0000;HP=1;HapScore=1;MGOF=5;MMLQ...  GT:GL:GOF:GQ:NR:NV   \n",
       "4  BRF=0.17;FR=1.0000;HP=2;HapScore=1;MGOF=3;MMLQ...  GT:GL:GOF:GQ:NR:NV   \n",
       "\n",
       "                               sample  \n",
       "0  1/1:-300.0,-43.88,0.0:3:99:160:156  \n",
       "1  1/1:-300.0,-41.24,0.0:5:99:152:148  \n",
       "2  1/1:-300.0,-37.63,0.0:3:99:137:135  \n",
       "3  1/1:-300.0,-39.74,0.0:5:99:136:134  \n",
       "4  1/1:-300.0,-39.41,0.0:3:99:137:133  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put lines after headers into dataframe\n",
    "df = pd.read_csv(filename + '.txt', sep='\\t', skiprows=headercount)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "339fa54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data in FORMAT and sample columns into separate columns\n",
    "# match FORMAT ID to corresponding sample value column\n",
    "\n",
    "formatdf = pd.DataFrame(list(df.FORMAT.str.split(':')))\n",
    "#print(formatdf.describe())\n",
    "sampledf = pd.DataFrame(list(df['sample'].str.split(':')))\n",
    "#print(sampledf.describe())\n",
    "\n",
    "# rename columns with FORMAT ID\n",
    "formatid = list(formatdf.iloc[0,:])\n",
    "sampledf.columns = formatid\n",
    "#sampledf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f6a8272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unformatted and extra columns, add in parsed column\n",
    "\n",
    "df = df.drop(['ID','INFO','FORMAT', 'sample'], axis=1)\n",
    "df = pd.concat([df, sampledf], axis=1)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "740b87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column data types to allow later data operations\n",
    "\n",
    "for col in ['NV', 'NR']:\n",
    "    df[col] = df[col].str.replace(',','').astype(int)\n",
    "for col in ['#CHROM','REF', 'ALT']:\n",
    "    df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e693199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate column for percentage reads supporting variant\n",
    "\n",
    "df['NV/NR'] = df['NV']/df['NR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a2bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine type of variant\n",
    "# inputs: reference base(s) and alternate base(s) from VCF\n",
    "# outputs: type of variant\n",
    "# currently, only identifies some variant types\n",
    "\n",
    "def get_variant_type(REF, ALT):\n",
    "    if (len(REF) == 1) and (len(ALT) == 1):\n",
    "        vartype = 'substitution'\n",
    "        \n",
    "    elif (len(REF) == 1) and (len(ALT) > 1):\n",
    "        vartype = 'insertion'\n",
    "            \n",
    "    elif len(REF) > len(ALT):\n",
    "        vartype = 'deletion'\n",
    "        \n",
    "    else:\n",
    "        # unknown variant type\n",
    "        vartype = 'unknown'\n",
    "        \n",
    "    return vartype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e0371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to put variant into hgvs notation\n",
    "# inputs:  chromosome, variant position, reference base(s), and alternate base(s) from VCF, \n",
    "# and variant type (from function get_variant_type)\n",
    "# outputs: hgvs notation\n",
    "# currently, only some variant types covered\n",
    "\n",
    "def get_hgvs_notation(chromosome, position, REF, ALT, varianttype):\n",
    "    # base\n",
    "    hgvs_part1 = chromosome + ':' + 'g.' + str(position)\n",
    "    \n",
    "    # variant specific\n",
    "    if varianttype == 'substitution':\n",
    "        hgvs_part2 = REF + '>' + ALT\n",
    "        \n",
    "    elif varianttype == 'insertion':\n",
    "        hgvs_part2 = '_' + str(position + 1) + 'ins' + ALT[1:]\n",
    "        \n",
    "    elif varianttype == 'deletion':\n",
    "        hgvs_part2 = '_' + str(position + len(REF) - 1) + 'del'\n",
    "        \n",
    "    else:\n",
    "        # unknown variant type\n",
    "        hgvs_part2 = ''\n",
    "        \n",
    "    if hgvs_part2 == '':\n",
    "        # put placeholder, ideally, all variant types put into proper hgvs notation\n",
    "        hgvs_notation = '1:g.25362501C>A'\n",
    "    else:\n",
    "        hgvs_notation = hgvs_part1 + hgvs_part2\n",
    "    \n",
    "    return hgvs_notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "535ff0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process Ensembl VEP hgvs API response from POST request\n",
    "# input: response from API as dict, processed by json.loads()\n",
    "# outputs: lists of gene symbol, most severe consequence, and minor allele frequency for each variant in input data\n",
    "\n",
    "def get_info(data):\n",
    "    gene = []\n",
    "    effect = []\n",
    "    minoralfreq = []\n",
    "\n",
    "    for item in range(len(data)):\n",
    "        # get gene, if available\n",
    "        if 'transcript_consequences' in data[item] \\\n",
    "        and 'gene_symbol' in data[item]['transcript_consequences'][0]:\n",
    "            gene.append(data[item]['transcript_consequences'][0]['gene_symbol'])\n",
    "        else:\n",
    "            gene.append('unknown')\n",
    "\n",
    "        # get effect, if available\n",
    "        if 'most_severe_consequence' in data[item]:\n",
    "            effect.append(data[item]['most_severe_consequence'])\n",
    "        else:\n",
    "            effect.append('unknown')\n",
    "\n",
    "        # get minor allele frequency, if available\n",
    "        if 'colocated_variants' in data[item] \\\n",
    "        and ('minor_allele_freq' in data[item]['colocated_variants'][0]):\n",
    "            minoralfreq.append(data[item]['colocated_variants'][0]['minor_allele_freq'])\n",
    "\n",
    "        elif 'colocated_variants' in data[item] \\\n",
    "        and (len(data[item]['colocated_variants']) > 1) \\\n",
    "        and ('minor_allele_freq' in data[item]['colocated_variants'][1]):\n",
    "            minoralfreq.append(data[item]['colocated_variants'][1]['minor_allele_freq'])\n",
    "        else:\n",
    "            minoralfreq.append('unknown')\n",
    "            \n",
    "    return gene, effect, minoralfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcea8871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  1\n",
      "make request...\n",
      "load response...\n",
      "batch:  2\n",
      "make request...\n",
      "load response...\n",
      "batch:  3\n",
      "make request...\n",
      "load response...\n",
      "batch:  4\n",
      "make request...\n",
      "load response...\n",
      "batch:  5\n",
      "make request...\n",
      "load response...\n",
      "batch:  6\n",
      "make request...\n",
      "load response...\n",
      "batch:  7\n",
      "make request...\n",
      "load response...\n",
      "batch:  8\n",
      "make request...\n",
      "load response...\n",
      "batch:  9\n",
      "make request...\n",
      "load response...\n",
      "batch:  10\n",
      "make request...\n",
      "load response...\n",
      "batch:  11\n",
      "make request...\n",
      "load response...\n",
      "batch:  12\n",
      "make request...\n",
      "load response...\n",
      "batch:  13\n",
      "make request...\n",
      "load response...\n",
      "batch:  14\n",
      "make request...\n",
      "load response...\n",
      "batch:  15\n",
      "make request...\n",
      "load response...\n",
      "batch:  16\n",
      "make request...\n",
      "load response...\n",
      "batch:  17\n",
      "make request...\n",
      "load response...\n",
      "batch:  18\n",
      "make request...\n",
      "load response...\n",
      "batch:  19\n",
      "make request...\n",
      "load response...\n",
      "batch:  20\n",
      "make request...\n",
      "load response...\n",
      "batch:  21\n",
      "make request...\n",
      "load response...\n",
      "batch:  22\n",
      "make request...\n",
      "load response...\n",
      "batch:  23\n",
      "make request...\n",
      "load response...\n",
      "batch:  24\n",
      "make request...\n",
      "load response...\n",
      "batch:  25\n",
      "make request...\n",
      "load response...\n",
      "batch:  26\n",
      "make request...\n",
      "load response...\n",
      "batch:  27\n",
      "make request...\n",
      "load response...\n",
      "batch:  28\n",
      "make request...\n",
      "load response...\n",
      "batch:  29\n",
      "make request...\n",
      "load response...\n",
      "batch:  30\n",
      "make request...\n",
      "load response...\n",
      "batch:  31\n",
      "make request...\n",
      "load response...\n",
      "batch:  32\n",
      "make request...\n",
      "load response...\n",
      "batch:  33\n",
      "make request...\n",
      "load response...\n",
      "batch:  34\n",
      "make request...\n",
      "load response...\n",
      "batch:  35\n",
      "make request...\n",
      "load response...\n",
      "batch:  36\n",
      "make request...\n",
      "load response...\n",
      "batch:  37\n",
      "make request...\n",
      "load response...\n",
      "batch:  38\n",
      "make request...\n",
      "load response...\n",
      "batch:  39\n",
      "make request...\n",
      "load response...\n",
      "batch:  40\n",
      "make request...\n",
      "load response...\n"
     ]
    }
   ],
   "source": [
    "# query api and get data\n",
    "\n",
    "count = 0\n",
    "typelist = []\n",
    "varlist = [] \n",
    "genelist = []\n",
    "effectlist = []\n",
    "minoralfreqlist = []\n",
    "\n",
    "for variant in range(len(df)):\n",
    "    \n",
    "    REF = df.loc[variant, 'REF'] # reference base(s)\n",
    "    ALT = df.loc[variant, 'ALT'] # alternate base(s)\n",
    "    POS = df.loc[variant, 'POS'] # variant position\n",
    "    CHROM = df.loc[variant, '#CHROM'] # chromosome\n",
    "    \n",
    "    # get type of variant\n",
    "    vartype = get_variant_type(REF, ALT)\n",
    "    typelist.append(vartype)\n",
    "    \n",
    "    # put variant into hgvs notation, make hgvs list for api query\n",
    "    varlist.append(get_hgvs_notation(CHROM, POS, REF, ALT, vartype))\n",
    "    \n",
    "    if len(varlist) >= 300 or variant == (len(df)-1):\n",
    "        # just to see progress or lack of\n",
    "        count += 1\n",
    "        print('batch: ', count)\n",
    "            \n",
    "        # query api\n",
    "        # since reference sequence is based off GRCh37, connect to grch37 site\n",
    "        url = 'https://grch37.rest.ensembl.org'\n",
    "        endpoint = '/vep/human/hgvs'\n",
    "        headers = {'Content-Type':'application/json', 'Accept':'application/json'}\n",
    "        hgvs_list = {'hgvs_notations': varlist}\n",
    "\n",
    "\n",
    "        # make request\n",
    "        for retry in range(5):\n",
    "            try:\n",
    "                print('make request...')\n",
    "                r = requests.post(url + endpoint, headers=headers, data=json.dumps(hgvs_list))\n",
    "                break\n",
    "\n",
    "            except requests.ConnectionError:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "\n",
    "        # get data if request successful\n",
    "        if r.status_code == 200:\n",
    "            print('load response...')\n",
    "            data = json.loads(r.text)\n",
    "            \n",
    "            # get info from response\n",
    "            gene, effect, minoralfreq = get_info(data)\n",
    "            \n",
    "            # join lists gathered from each response\n",
    "            genelist = genelist + gene\n",
    "            effectlist = effectlist + effect\n",
    "            minoralfreqlist = minoralfreqlist + minoralfreq\n",
    "            \n",
    "            # reset to empty for next batch    \n",
    "            varlist = []\n",
    "        else:\n",
    "            print(r.status_code)\n",
    "            print(r.headers)\n",
    "            \n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "#print(typelist)\n",
    "#print(genelist)\n",
    "#print(effectlist)\n",
    "#print(minoralfreqlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "680d1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in dataframe\n",
    "df['gene'] = genelist\n",
    "df['type'] = typelist\n",
    "df['effect'] = effectlist\n",
    "df['minor_allele_freq'] = minoralfreqlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c02723ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up dataframe a bit\n",
    "df = df.drop(['GT', 'GL','GOF', 'GQ'], axis=1)\n",
    "df['effect'] = df['effect'].str.replace('_',' ')\n",
    "df = df.rename(columns={'#CHROM': 'CHROM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cd4eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df.to_csv(filename.split('.')[0] + '_annotated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15efbe6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
